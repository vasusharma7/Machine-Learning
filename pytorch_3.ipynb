{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasusharma7/Machine-Learning/blob/master/pytorch_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDLv0343KWkD",
        "colab_type": "code",
        "outputId": "3f073424-25c0-4b4a-c8a6-b10cc0d69b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "!git clone https://github.com/jonas-koehler/s2cnn.git\n",
        "!git clone https://github.com/AMLab-Amsterdam/lie_learn.git\n",
        "import requests  \n",
        "file_url = \"https://drive.google.com/uc?export=download&confirm=gFeQ&id=0B5e7DAOiLEZwSkdfXzBYT29Nc3c\"\n",
        "    \n",
        "r = requests.get(file_url, stream = True)  \n",
        "  \n",
        "with open(\"lie_learn/lie_learn/representations/SO3/pinchon_hoggan/J_dense_0-278.npy\", \"wb\") as file:  \n",
        "    for block in r.iter_content(chunk_size = 1024): \n",
        "         if block:  \n",
        "             file.write(block)  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 's2cnn'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/25)\u001b[K\rremote: Counting objects:   8% (2/25)\u001b[K\rremote: Counting objects:  12% (3/25)\u001b[K\rremote: Counting objects:  16% (4/25)\u001b[K\rremote: Counting objects:  20% (5/25)\u001b[K\rremote: Counting objects:  24% (6/25)\u001b[K\rremote: Counting objects:  28% (7/25)\u001b[K\rremote: Counting objects:  32% (8/25)\u001b[K\rremote: Counting objects:  36% (9/25)\u001b[K\rremote: Counting objects:  40% (10/25)\u001b[K\rremote: Counting objects:  44% (11/25)\u001b[K\rremote: Counting objects:  48% (12/25)\u001b[K\rremote: Counting objects:  52% (13/25)\u001b[K\rremote: Counting objects:  56% (14/25)\u001b[K\rremote: Counting objects:  60% (15/25)\u001b[K\rremote: Counting objects:  64% (16/25)\u001b[K\rremote: Counting objects:  68% (17/25)\u001b[K\rremote: Counting objects:  72% (18/25)\u001b[K\rremote: Counting objects:  76% (19/25)\u001b[K\rremote: Counting objects:  80% (20/25)\u001b[K\rremote: Counting objects:  84% (21/25)\u001b[K\rremote: Counting objects:  88% (22/25)\u001b[K\rremote: Counting objects:  92% (23/25)\u001b[K\rremote: Counting objects:  96% (24/25)\u001b[K\rremote: Counting objects: 100% (25/25)\u001b[K\rremote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects:   4% (1/21)\u001b[K\rremote: Compressing objects:   9% (2/21)\u001b[K\rremote: Compressing objects:  14% (3/21)\u001b[K\rremote: Compressing objects:  19% (4/21)\u001b[K\rremote: Compressing objects:  23% (5/21)\u001b[K\rremote: Compressing objects:  28% (6/21)\u001b[K\rremote: Compressing objects:  33% (7/21)\u001b[K\rremote: Compressing objects:  38% (8/21)\u001b[K\rremote: Compressing objects:  42% (9/21)\u001b[K\rremote: Compressing objects:  47% (10/21)\u001b[K\rremote: Compressing objects:  52% (11/21)\u001b[K\rremote: Compressing objects:  57% (12/21)\u001b[K\rremote: Compressing objects:  61% (13/21)\u001b[K\rremote: Compressing objects:  66% (14/21)\u001b[K\rremote: Compressing objects:  71% (15/21)\u001b[K\rremote: Compressing objects:  76% (16/21)\u001b[K\rremote: Compressing objects:  80% (17/21)\u001b[K\rremote: Compressing objects:  85% (18/21)\u001b[K\rremote: Compressing objects:  90% (19/21)\u001b[K\rremote: Compressing objects:  95% (20/21)\u001b[K\rremote: Compressing objects: 100% (21/21)\u001b[K\rremote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "Receiving objects:   0% (1/800)   \rReceiving objects:   1% (8/800)   \rReceiving objects:   2% (16/800)   \rReceiving objects:   3% (24/800)   \rReceiving objects:   4% (32/800)   \rReceiving objects:   5% (40/800)   \rReceiving objects:   6% (48/800)   \rReceiving objects:   7% (56/800)   \rReceiving objects:   8% (64/800)   \rReceiving objects:   9% (72/800)   \rReceiving objects:  10% (80/800)   \rReceiving objects:  11% (88/800)   \rReceiving objects:  12% (96/800)   \rReceiving objects:  13% (104/800)   \rReceiving objects:  14% (112/800)   \rReceiving objects:  15% (120/800)   \rReceiving objects:  16% (128/800)   \rReceiving objects:  17% (136/800)   \rReceiving objects:  18% (144/800)   \rReceiving objects:  19% (152/800)   \rReceiving objects:  20% (160/800)   \rReceiving objects:  21% (168/800)   \rReceiving objects:  22% (176/800)   \rReceiving objects:  23% (184/800)   \rReceiving objects:  24% (192/800)   \rReceiving objects:  25% (200/800)   \rReceiving objects:  26% (208/800)   \rReceiving objects:  27% (216/800)   \rReceiving objects:  28% (224/800)   \rReceiving objects:  29% (232/800)   \rReceiving objects:  30% (240/800)   \rReceiving objects:  31% (248/800)   \rReceiving objects:  32% (256/800)   \rReceiving objects:  33% (264/800)   \rReceiving objects:  34% (272/800)   \rReceiving objects:  35% (280/800)   \rReceiving objects:  36% (288/800)   \rReceiving objects:  37% (296/800)   \rReceiving objects:  38% (304/800)   \rReceiving objects:  39% (312/800)   \rReceiving objects:  40% (320/800)   \rReceiving objects:  41% (328/800)   \rReceiving objects:  42% (336/800)   \rReceiving objects:  43% (344/800)   \rReceiving objects:  44% (352/800)   \rReceiving objects:  45% (360/800)   \rReceiving objects:  46% (368/800)   \rReceiving objects:  47% (376/800)   \rReceiving objects:  48% (384/800)   \rReceiving objects:  49% (392/800)   \rReceiving objects:  50% (400/800)   \rReceiving objects:  51% (408/800)   \rReceiving objects:  52% (416/800)   \rReceiving objects:  53% (424/800)   \rReceiving objects:  54% (432/800)   \rReceiving objects:  55% (440/800)   \rReceiving objects:  56% (448/800)   \rReceiving objects:  57% (456/800)   \rReceiving objects:  58% (464/800)   \rReceiving objects:  59% (472/800)   \rReceiving objects:  60% (480/800)   \rReceiving objects:  61% (488/800)   \rReceiving objects:  62% (496/800)   \rReceiving objects:  63% (504/800)   \rReceiving objects:  64% (512/800)   \rReceiving objects:  65% (520/800)   \rReceiving objects:  66% (528/800)   \rReceiving objects:  67% (536/800)   \rremote: Total 800 (delta 6), reused 10 (delta 4), pack-reused 775\u001b[K\n",
            "Receiving objects:  68% (544/800)   \rReceiving objects:  69% (552/800)   \rReceiving objects:  70% (560/800)   \rReceiving objects:  71% (568/800)   \rReceiving objects:  72% (576/800)   \rReceiving objects:  73% (584/800)   \rReceiving objects:  74% (592/800)   \rReceiving objects:  75% (600/800)   \rReceiving objects:  76% (608/800)   \rReceiving objects:  77% (616/800)   \rReceiving objects:  78% (624/800)   \rReceiving objects:  79% (632/800)   \rReceiving objects:  80% (640/800)   \rReceiving objects:  81% (648/800)   \rReceiving objects:  82% (656/800)   \rReceiving objects:  83% (664/800)   \rReceiving objects:  84% (672/800)   \rReceiving objects:  85% (680/800)   \rReceiving objects:  86% (688/800)   \rReceiving objects:  87% (696/800)   \rReceiving objects:  88% (704/800)   \rReceiving objects:  89% (712/800)   \rReceiving objects:  90% (720/800)   \rReceiving objects:  91% (728/800)   \rReceiving objects:  92% (736/800)   \rReceiving objects:  93% (744/800)   \rReceiving objects:  94% (752/800)   \rReceiving objects:  95% (760/800)   \rReceiving objects:  96% (768/800)   \rReceiving objects:  97% (776/800)   \rReceiving objects:  98% (784/800)   \rReceiving objects:  99% (792/800)   \rReceiving objects: 100% (800/800)   \rReceiving objects: 100% (800/800), 944.62 KiB | 26.24 MiB/s, done.\n",
            "Resolving deltas: 100% (418/418), done.\n",
            "Cloning into 'lie_learn'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 335 (delta 13), reused 15 (delta 6), pack-reused 299\u001b[K\n",
            "Receiving objects: 100% (335/335), 206.10 KiB | 14.72 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8EFLqosKwRg",
        "colab_type": "code",
        "outputId": "40820926-d151-412d-ad4c-a9331134c641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd s2cnn\n",
        "!python setup.py install\n",
        "%cd ../lie_learn\n",
        "!python setup.py install\n",
        "%cd ..\n",
        "!pip install pynvrtc joblib"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/s2cnn\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating s2cnn.egg-info\n",
            "writing s2cnn.egg-info/PKG-INFO\n",
            "writing dependency_links to s2cnn.egg-info/dependency_links.txt\n",
            "writing top-level names to s2cnn.egg-info/top_level.txt\n",
            "writing manifest file 's2cnn.egg-info/SOURCES.txt'\n",
            "writing manifest file 's2cnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/s2cnn\n",
            "copying s2cnn/so3_ft.py -> build/lib/s2cnn\n",
            "copying s2cnn/so3_grid.py -> build/lib/s2cnn\n",
            "copying s2cnn/so3_mm.py -> build/lib/s2cnn\n",
            "copying s2cnn/s2_grid.py -> build/lib/s2cnn\n",
            "copying s2cnn/s2_ft.py -> build/lib/s2cnn\n",
            "copying s2cnn/s2_mm.py -> build/lib/s2cnn\n",
            "copying s2cnn/__init__.py -> build/lib/s2cnn\n",
            "creating build/lib/s2cnn/soft\n",
            "copying s2cnn/soft/so3_integrate.py -> build/lib/s2cnn/soft\n",
            "copying s2cnn/soft/so3_fft.py -> build/lib/s2cnn/soft\n",
            "copying s2cnn/soft/so3_rotation.py -> build/lib/s2cnn/soft\n",
            "copying s2cnn/soft/so3_conv.py -> build/lib/s2cnn/soft\n",
            "copying s2cnn/soft/__init__.py -> build/lib/s2cnn/soft\n",
            "copying s2cnn/soft/s2_conv.py -> build/lib/s2cnn/soft\n",
            "copying s2cnn/soft/s2_fft.py -> build/lib/s2cnn/soft\n",
            "creating build/lib/s2cnn/utils\n",
            "copying s2cnn/utils/complex.py -> build/lib/s2cnn/utils\n",
            "copying s2cnn/utils/cuda.py -> build/lib/s2cnn/utils\n",
            "copying s2cnn/utils/__init__.py -> build/lib/s2cnn/utils\n",
            "copying s2cnn/utils/decorator.py -> build/lib/s2cnn/utils\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/s2cnn\n",
            "copying build/lib/s2cnn/so3_ft.py -> build/bdist.linux-x86_64/egg/s2cnn\n",
            "creating build/bdist.linux-x86_64/egg/s2cnn/soft\n",
            "copying build/lib/s2cnn/soft/so3_integrate.py -> build/bdist.linux-x86_64/egg/s2cnn/soft\n",
            "copying build/lib/s2cnn/soft/so3_fft.py -> build/bdist.linux-x86_64/egg/s2cnn/soft\n",
            "copying build/lib/s2cnn/soft/so3_rotation.py -> build/bdist.linux-x86_64/egg/s2cnn/soft\n",
            "copying build/lib/s2cnn/soft/so3_conv.py -> build/bdist.linux-x86_64/egg/s2cnn/soft\n",
            "copying build/lib/s2cnn/soft/__init__.py -> build/bdist.linux-x86_64/egg/s2cnn/soft\n",
            "copying build/lib/s2cnn/soft/s2_conv.py -> build/bdist.linux-x86_64/egg/s2cnn/soft\n",
            "copying build/lib/s2cnn/soft/s2_fft.py -> build/bdist.linux-x86_64/egg/s2cnn/soft\n",
            "creating build/bdist.linux-x86_64/egg/s2cnn/utils\n",
            "copying build/lib/s2cnn/utils/complex.py -> build/bdist.linux-x86_64/egg/s2cnn/utils\n",
            "copying build/lib/s2cnn/utils/cuda.py -> build/bdist.linux-x86_64/egg/s2cnn/utils\n",
            "copying build/lib/s2cnn/utils/__init__.py -> build/bdist.linux-x86_64/egg/s2cnn/utils\n",
            "copying build/lib/s2cnn/utils/decorator.py -> build/bdist.linux-x86_64/egg/s2cnn/utils\n",
            "copying build/lib/s2cnn/so3_grid.py -> build/bdist.linux-x86_64/egg/s2cnn\n",
            "copying build/lib/s2cnn/so3_mm.py -> build/bdist.linux-x86_64/egg/s2cnn\n",
            "copying build/lib/s2cnn/s2_grid.py -> build/bdist.linux-x86_64/egg/s2cnn\n",
            "copying build/lib/s2cnn/s2_ft.py -> build/bdist.linux-x86_64/egg/s2cnn\n",
            "copying build/lib/s2cnn/s2_mm.py -> build/bdist.linux-x86_64/egg/s2cnn\n",
            "copying build/lib/s2cnn/__init__.py -> build/bdist.linux-x86_64/egg/s2cnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/so3_ft.py to so3_ft.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/soft/so3_integrate.py to so3_integrate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/soft/so3_fft.py to so3_fft.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/soft/so3_rotation.py to so3_rotation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/soft/so3_conv.py to so3_conv.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/soft/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/soft/s2_conv.py to s2_conv.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/soft/s2_fft.py to s2_fft.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/utils/complex.py to complex.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/utils/cuda.py to cuda.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/utils/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/utils/decorator.py to decorator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/so3_grid.py to so3_grid.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/so3_mm.py to so3_mm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/s2_grid.py to s2_grid.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/s2_ft.py to s2_ft.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/s2_mm.py to s2_mm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/s2cnn/__init__.py to __init__.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying s2cnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying s2cnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying s2cnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying s2cnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/s2cnn-1.0.0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing s2cnn-1.0.0-py3.6.egg\n",
            "Copying s2cnn-1.0.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding s2cnn 1.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/s2cnn-1.0.0-py3.6.egg\n",
            "Processing dependencies for s2cnn==1.0.0\n",
            "Finished processing dependencies for s2cnn==1.0.0\n",
            "/content/lie_learn\n",
            "Compiling lie_learn/groups/SO3.pyx because it changed.\n",
            "Compiling lie_learn/representations/SO3/irrep_bases.pyx because it changed.\n",
            "Compiling lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan.pyx because it changed.\n",
            "Compiling lie_learn/spaces/spherical_quadrature.pyx because it changed.\n",
            "[1/4] Cythonizing lie_learn/groups/SO3.pyx\n",
            "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/lie_learn/lie_learn/groups/SO3.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "warning: lie_learn/groups/SO3.pyx:100:8: Unreachable code\n",
            "[2/4] Cythonizing lie_learn/representations/SO3/irrep_bases.pyx\n",
            "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/lie_learn/lie_learn/representations/SO3/irrep_bases.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "[3/4] Cythonizing lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan.pyx\n",
            "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/lie_learn/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "[4/4] Cythonizing lie_learn/spaces/spherical_quadrature.pyx\n",
            "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/lie_learn/lie_learn/spaces/spherical_quadrature.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/lie_learn\n",
            "copying lie_learn/broadcasting.py -> build/lib.linux-x86_64-3.6/lie_learn\n",
            "copying lie_learn/__init__.py -> build/lib.linux-x86_64-3.6/lie_learn\n",
            "creating build/lib.linux-x86_64-3.6/lie_learn/representations\n",
            "copying lie_learn/representations/__init__.py -> build/lib.linux-x86_64-3.6/lie_learn/representations\n",
            "creating build/lib.linux-x86_64-3.6/lie_learn/spaces\n",
            "copying lie_learn/spaces/S2.py -> build/lib.linux-x86_64-3.6/lie_learn/spaces\n",
            "copying lie_learn/spaces/S3.py -> build/lib.linux-x86_64-3.6/lie_learn/spaces\n",
            "copying lie_learn/spaces/rn.py -> build/lib.linux-x86_64-3.6/lie_learn/spaces\n",
            "copying lie_learn/spaces/Tn.py -> build/lib.linux-x86_64-3.6/lie_learn/spaces\n",
            "copying lie_learn/spaces/__init__.py -> build/lib.linux-x86_64-3.6/lie_learn/spaces\n",
            "creating build/lib.linux-x86_64-3.6/lie_learn/probability\n",
            "copying lie_learn/probability/__init__.py -> build/lib.linux-x86_64-3.6/lie_learn/probability\n",
            "copying lie_learn/probability/S2HarmonicDensity.py -> build/lib.linux-x86_64-3.6/lie_learn/probability\n",
            "copying lie_learn/probability/SO3HarmonicDensity.py -> build/lib.linux-x86_64-3.6/lie_learn/probability\n",
            "copying lie_learn/probability/S1HarmonicDensity.py -> build/lib.linux-x86_64-3.6/lie_learn/probability\n",
            "copying lie_learn/probability/HarmonicDensity.py -> build/lib.linux-x86_64-3.6/lie_learn/probability\n",
            "creating build/lib.linux-x86_64-3.6/lie_learn/groups\n",
            "copying lie_learn/groups/SO2.py -> build/lib.linux-x86_64-3.6/lie_learn/groups\n",
            "copying lie_learn/groups/SO3_tests.py -> build/lib.linux-x86_64-3.6/lie_learn/groups\n",
            "copying lie_learn/groups/SE2.py -> build/lib.linux-x86_64-3.6/lie_learn/groups\n",
            "copying lie_learn/groups/__init__.py -> build/lib.linux-x86_64-3.6/lie_learn/groups\n",
            "creating build/lib.linux-x86_64-3.6/lie_learn/spectral\n",
            "copying lie_learn/spectral/SO3FFT_Naive.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral\n",
            "copying lie_learn/spectral/PolarFFT.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral\n",
            "copying lie_learn/spectral/S2FFT.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral\n",
            "copying lie_learn/spectral/S2_conv.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral\n",
            "copying lie_learn/spectral/FFTBase.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral\n",
            "copying lie_learn/spectral/S2FFT_NFFT.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral\n",
            "copying lie_learn/spectral/__init__.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral\n",
            "copying lie_learn/spectral/SO3_conv.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral\n",
            "copying lie_learn/spectral/SE2FFT.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral\n",
            "copying lie_learn/spectral/T2FFT.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral\n",
            "copying lie_learn/spectral/T1FFT.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral\n",
            "copying lie_learn/spectral/fourier_interpolation.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral\n",
            "creating build/lib.linux-x86_64-3.6/lie_learn/representations/SO3\n",
            "copying lie_learn/representations/SO3/indexing.py -> build/lib.linux-x86_64-3.6/lie_learn/representations/SO3\n",
            "copying lie_learn/representations/SO3/test_wigner_d.py -> build/lib.linux-x86_64-3.6/lie_learn/representations/SO3\n",
            "copying lie_learn/representations/SO3/spherical_harmonics.py -> build/lib.linux-x86_64-3.6/lie_learn/representations/SO3\n",
            "copying lie_learn/representations/SO3/clebsch_gordan_numerical.py -> build/lib.linux-x86_64-3.6/lie_learn/representations/SO3\n",
            "copying lie_learn/representations/SO3/test_SO3_irrep_bases.py -> build/lib.linux-x86_64-3.6/lie_learn/representations/SO3\n",
            "copying lie_learn/representations/SO3/__init__.py -> build/lib.linux-x86_64-3.6/lie_learn/representations/SO3\n",
            "copying lie_learn/representations/SO3/wigner_d.py -> build/lib.linux-x86_64-3.6/lie_learn/representations/SO3\n",
            "copying lie_learn/representations/SO3/test_spherical_harmonics.py -> build/lib.linux-x86_64-3.6/lie_learn/representations/SO3\n",
            "creating build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan\n",
            "copying lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan_dense.py -> build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan\n",
            "copying lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan_parsing.py -> build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan\n",
            "copying lie_learn/representations/SO3/pinchon_hoggan/__init__.py -> build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan\n",
            "creating build/lib.linux-x86_64-3.6/lie_learn/spaces/tests\n",
            "copying lie_learn/spaces/tests/test_spherical_quadrature.py -> build/lib.linux-x86_64-3.6/lie_learn/spaces/tests\n",
            "copying lie_learn/spaces/tests/__init__.py -> build/lib.linux-x86_64-3.6/lie_learn/spaces/tests\n",
            "copying lie_learn/spaces/tests/test_S3_quadrature.py -> build/lib.linux-x86_64-3.6/lie_learn/spaces/tests\n",
            "creating build/lib.linux-x86_64-3.6/lie_learn/spectral/tests\n",
            "copying lie_learn/spectral/tests/test_S2FFT.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral/tests\n",
            "copying lie_learn/spectral/tests/test_S2_conv.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral/tests\n",
            "copying lie_learn/spectral/tests/test_SO3_FFT_Naive.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral/tests\n",
            "copying lie_learn/spectral/tests/test_conv_S2_SO3.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral/tests\n",
            "copying lie_learn/spectral/tests/test_S2FFT_NFFT.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral/tests\n",
            "copying lie_learn/spectral/tests/__init__.py -> build/lib.linux-x86_64-3.6/lie_learn/spectral/tests\n",
            "running build_ext\n",
            "building 'lie_learn.groups.SO3' extension\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/lie_learn\n",
            "creating build/temp.linux-x86_64-3.6/lie_learn/groups\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c lie_learn/groups/SO3.c -o build/temp.linux-x86_64-3.6/lie_learn/groups/SO3.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1830:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Klie_learn/groups/SO3.c:611\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/lie_learn/groups/SO3.o -o build/lib.linux-x86_64-3.6/lie_learn/groups/SO3.cpython-36m-x86_64-linux-gnu.so\n",
            "building 'lie_learn.representations.SO3.irrep_bases' extension\n",
            "creating build/temp.linux-x86_64-3.6/lie_learn/representations\n",
            "creating build/temp.linux-x86_64-3.6/lie_learn/representations/SO3\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c lie_learn/representations/SO3/irrep_bases.c -o build/temp.linux-x86_64-3.6/lie_learn/representations/SO3/irrep_bases.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1830:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Klie_learn/representations/SO3/irrep_bases.c:611\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/lie_learn/representations/SO3/irrep_bases.o -o build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/irrep_bases.cpython-36m-x86_64-linux-gnu.so\n",
            "building 'lie_learn.representations.SO3.pinchon_hoggan.pinchon_hoggan' extension\n",
            "creating build/temp.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan.c -o build/temp.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1830:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Klie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan.c:611\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan.o -o build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan.cpython-36m-x86_64-linux-gnu.so\n",
            "building 'lie_learn.spaces.spherical_quadrature' extension\n",
            "creating build/temp.linux-x86_64-3.6/lie_learn/spaces\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c lie_learn/spaces/spherical_quadrature.c -o build/temp.linux-x86_64-3.6/lie_learn/spaces/spherical_quadrature.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1830:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Klie_learn/spaces/spherical_quadrature.c:611\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/lie_learn/spaces/spherical_quadrature.o -o build/lib.linux-x86_64-3.6/lie_learn/spaces/spherical_quadrature.cpython-36m-x86_64-linux-gnu.so\n",
            "running install_lib\n",
            "creating /usr/local/lib/python3.6/dist-packages/lie_learn\n",
            "creating /usr/local/lib/python3.6/dist-packages/lie_learn/representations\n",
            "creating /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/indexing.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/test_wigner_d.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/spherical_harmonics.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3\n",
            "creating /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/pinchon_hoggan\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan_dense.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/pinchon_hoggan\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan_parsing.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/pinchon_hoggan\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/pinchon_hoggan\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan/__init__.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/pinchon_hoggan\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/clebsch_gordan_numerical.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/test_SO3_irrep_bases.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/__init__.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/irrep_bases.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/wigner_d.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/test_spherical_harmonics.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/__init__.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/representations\n",
            "creating /usr/local/lib/python3.6/dist-packages/lie_learn/spaces\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/spherical_quadrature.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages/lie_learn/spaces\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/S2.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spaces\n",
            "creating /usr/local/lib/python3.6/dist-packages/lie_learn/spaces/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/tests/test_spherical_quadrature.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spaces/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/tests/__init__.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spaces/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/tests/test_S3_quadrature.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spaces/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/S3.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spaces\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/rn.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spaces\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/Tn.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spaces\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/__init__.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spaces\n",
            "creating /usr/local/lib/python3.6/dist-packages/lie_learn/probability\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/probability/__init__.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/probability\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/probability/S2HarmonicDensity.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/probability\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/probability/SO3HarmonicDensity.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/probability\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/probability/S1HarmonicDensity.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/probability\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/probability/HarmonicDensity.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/probability\n",
            "creating /usr/local/lib/python3.6/dist-packages/lie_learn/groups\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/groups/SO2.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/groups\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/groups/SO3_tests.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/groups\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/groups/SO3.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages/lie_learn/groups\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/groups/SE2.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/groups\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/groups/__init__.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/groups\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/broadcasting.py -> /usr/local/lib/python3.6/dist-packages/lie_learn\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/__init__.py -> /usr/local/lib/python3.6/dist-packages/lie_learn\n",
            "creating /usr/local/lib/python3.6/dist-packages/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/SO3FFT_Naive.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/PolarFFT.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/S2FFT.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/S2_conv.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/FFTBase.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral\n",
            "creating /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/tests/test_S2FFT.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/tests/test_S2_conv.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/tests/test_SO3_FFT_Naive.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/tests/test_conv_S2_SO3.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/tests/test_S2FFT_NFFT.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/tests/__init__.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/S2FFT_NFFT.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/__init__.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/SO3_conv.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/SE2FFT.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/T2FFT.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/T1FFT.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/fourier_interpolation.py -> /usr/local/lib/python3.6/dist-packages/lie_learn/spectral\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/indexing.py to indexing.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/test_wigner_d.py to test_wigner_d.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/spherical_harmonics.py to spherical_harmonics.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan_dense.py to pinchon_hoggan_dense.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan_parsing.py to pinchon_hoggan_parsing.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/pinchon_hoggan/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/clebsch_gordan_numerical.py to clebsch_gordan_numerical.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/test_SO3_irrep_bases.py to test_SO3_irrep_bases.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/wigner_d.py to wigner_d.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/test_spherical_harmonics.py to test_spherical_harmonics.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/representations/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spaces/S2.py to S2.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spaces/tests/test_spherical_quadrature.py to test_spherical_quadrature.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spaces/tests/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spaces/tests/test_S3_quadrature.py to test_S3_quadrature.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spaces/S3.py to S3.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spaces/rn.py to rn.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spaces/Tn.py to Tn.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spaces/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/probability/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/probability/S2HarmonicDensity.py to S2HarmonicDensity.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/probability/SO3HarmonicDensity.py to SO3HarmonicDensity.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/probability/S1HarmonicDensity.py to S1HarmonicDensity.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/probability/HarmonicDensity.py to HarmonicDensity.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/groups/SO2.py to SO2.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/groups/SO3_tests.py to SO3_tests.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/groups/SE2.py to SE2.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/groups/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/broadcasting.py to broadcasting.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/SO3FFT_Naive.py to SO3FFT_Naive.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/PolarFFT.py to PolarFFT.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/S2FFT.py to S2FFT.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/S2_conv.py to S2_conv.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/FFTBase.py to FFTBase.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/tests/test_S2FFT.py to test_S2FFT.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/tests/test_S2_conv.py to test_S2_conv.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/tests/test_SO3_FFT_Naive.py to test_SO3_FFT_Naive.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/tests/test_conv_S2_SO3.py to test_conv_S2_SO3.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/tests/test_S2FFT_NFFT.py to test_S2FFT_NFFT.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/tests/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/S2FFT_NFFT.py to S2FFT_NFFT.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/SO3_conv.py to SO3_conv.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/SE2FFT.py to SE2FFT.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/T2FFT.py to T2FFT.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/T1FFT.py to T1FFT.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lie_learn/spectral/fourier_interpolation.py to fourier_interpolation.cpython-36.pyc\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "creating lie_learn.egg-info\n",
            "writing lie_learn.egg-info/PKG-INFO\n",
            "writing dependency_links to lie_learn.egg-info/dependency_links.txt\n",
            "writing requirements to lie_learn.egg-info/requires.txt\n",
            "writing top-level names to lie_learn.egg-info/top_level.txt\n",
            "writing manifest file 'lie_learn.egg-info/SOURCES.txt'\n",
            "writing manifest file 'lie_learn.egg-info/SOURCES.txt'\n",
            "Copying lie_learn.egg-info to /usr/local/lib/python3.6/dist-packages/lie_learn-0.0.0-py3.6.egg-info\n",
            "running install_scripts\n",
            "running bdist_egg\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/lie_learn\n",
            "creating build/bdist.linux-x86_64/egg/lie_learn/representations\n",
            "creating build/bdist.linux-x86_64/egg/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/indexing.py -> build/bdist.linux-x86_64/egg/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/test_wigner_d.py -> build/bdist.linux-x86_64/egg/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/spherical_harmonics.py -> build/bdist.linux-x86_64/egg/lie_learn/representations/SO3\n",
            "creating build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/pinchon_hoggan\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan_dense.py -> build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/pinchon_hoggan\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan_parsing.py -> build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/pinchon_hoggan\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/pinchon_hoggan\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/pinchon_hoggan/__init__.py -> build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/pinchon_hoggan\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/clebsch_gordan_numerical.py -> build/bdist.linux-x86_64/egg/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/test_SO3_irrep_bases.py -> build/bdist.linux-x86_64/egg/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/__init__.py -> build/bdist.linux-x86_64/egg/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/irrep_bases.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/wigner_d.py -> build/bdist.linux-x86_64/egg/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/SO3/test_spherical_harmonics.py -> build/bdist.linux-x86_64/egg/lie_learn/representations/SO3\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/representations/__init__.py -> build/bdist.linux-x86_64/egg/lie_learn/representations\n",
            "creating build/bdist.linux-x86_64/egg/lie_learn/spaces\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/spherical_quadrature.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/lie_learn/spaces\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/S2.py -> build/bdist.linux-x86_64/egg/lie_learn/spaces\n",
            "creating build/bdist.linux-x86_64/egg/lie_learn/spaces/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/tests/test_spherical_quadrature.py -> build/bdist.linux-x86_64/egg/lie_learn/spaces/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/tests/__init__.py -> build/bdist.linux-x86_64/egg/lie_learn/spaces/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/tests/test_S3_quadrature.py -> build/bdist.linux-x86_64/egg/lie_learn/spaces/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/S3.py -> build/bdist.linux-x86_64/egg/lie_learn/spaces\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/rn.py -> build/bdist.linux-x86_64/egg/lie_learn/spaces\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/Tn.py -> build/bdist.linux-x86_64/egg/lie_learn/spaces\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spaces/__init__.py -> build/bdist.linux-x86_64/egg/lie_learn/spaces\n",
            "creating build/bdist.linux-x86_64/egg/lie_learn/probability\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/probability/__init__.py -> build/bdist.linux-x86_64/egg/lie_learn/probability\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/probability/S2HarmonicDensity.py -> build/bdist.linux-x86_64/egg/lie_learn/probability\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/probability/SO3HarmonicDensity.py -> build/bdist.linux-x86_64/egg/lie_learn/probability\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/probability/S1HarmonicDensity.py -> build/bdist.linux-x86_64/egg/lie_learn/probability\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/probability/HarmonicDensity.py -> build/bdist.linux-x86_64/egg/lie_learn/probability\n",
            "creating build/bdist.linux-x86_64/egg/lie_learn/groups\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/groups/SO2.py -> build/bdist.linux-x86_64/egg/lie_learn/groups\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/groups/SO3_tests.py -> build/bdist.linux-x86_64/egg/lie_learn/groups\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/groups/SO3.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/lie_learn/groups\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/groups/SE2.py -> build/bdist.linux-x86_64/egg/lie_learn/groups\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/groups/__init__.py -> build/bdist.linux-x86_64/egg/lie_learn/groups\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/broadcasting.py -> build/bdist.linux-x86_64/egg/lie_learn\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/__init__.py -> build/bdist.linux-x86_64/egg/lie_learn\n",
            "creating build/bdist.linux-x86_64/egg/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/SO3FFT_Naive.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/PolarFFT.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/S2FFT.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/S2_conv.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/FFTBase.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral\n",
            "creating build/bdist.linux-x86_64/egg/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/tests/test_S2FFT.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/tests/test_S2_conv.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/tests/test_SO3_FFT_Naive.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/tests/test_conv_S2_SO3.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/tests/test_S2FFT_NFFT.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/tests/__init__.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral/tests\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/S2FFT_NFFT.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/__init__.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/SO3_conv.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/SE2FFT.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/T2FFT.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/T1FFT.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral\n",
            "copying build/lib.linux-x86_64-3.6/lie_learn/spectral/fourier_interpolation.py -> build/bdist.linux-x86_64/egg/lie_learn/spectral\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/indexing.py to indexing.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/test_wigner_d.py to test_wigner_d.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/spherical_harmonics.py to spherical_harmonics.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan_dense.py to pinchon_hoggan_dense.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan_parsing.py to pinchon_hoggan_parsing.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/pinchon_hoggan/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/clebsch_gordan_numerical.py to clebsch_gordan_numerical.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/test_SO3_irrep_bases.py to test_SO3_irrep_bases.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/wigner_d.py to wigner_d.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/test_spherical_harmonics.py to test_spherical_harmonics.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spaces/S2.py to S2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spaces/tests/test_spherical_quadrature.py to test_spherical_quadrature.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spaces/tests/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spaces/tests/test_S3_quadrature.py to test_S3_quadrature.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spaces/S3.py to S3.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spaces/rn.py to rn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spaces/Tn.py to Tn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spaces/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/probability/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/probability/S2HarmonicDensity.py to S2HarmonicDensity.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/probability/SO3HarmonicDensity.py to SO3HarmonicDensity.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/probability/S1HarmonicDensity.py to S1HarmonicDensity.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/probability/HarmonicDensity.py to HarmonicDensity.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/groups/SO2.py to SO2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/groups/SO3_tests.py to SO3_tests.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/groups/SE2.py to SE2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/groups/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/broadcasting.py to broadcasting.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/SO3FFT_Naive.py to SO3FFT_Naive.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/PolarFFT.py to PolarFFT.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/S2FFT.py to S2FFT.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/S2_conv.py to S2_conv.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/FFTBase.py to FFTBase.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/tests/test_S2FFT.py to test_S2FFT.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/tests/test_S2_conv.py to test_S2_conv.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/tests/test_SO3_FFT_Naive.py to test_SO3_FFT_Naive.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/tests/test_conv_S2_SO3.py to test_conv_S2_SO3.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/tests/test_S2FFT_NFFT.py to test_S2FFT_NFFT.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/tests/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/S2FFT_NFFT.py to S2FFT_NFFT.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/SO3_conv.py to SO3_conv.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/SE2FFT.py to SE2FFT.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/T2FFT.py to T2FFT.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/T1FFT.py to T1FFT.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spectral/fourier_interpolation.py to fourier_interpolation.cpython-36.pyc\n",
            "creating stub loader for lie_learn/groups/SO3.cpython-36m-x86_64-linux-gnu.so\n",
            "creating stub loader for lie_learn/representations/SO3/irrep_bases.cpython-36m-x86_64-linux-gnu.so\n",
            "creating stub loader for lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan.cpython-36m-x86_64-linux-gnu.so\n",
            "creating stub loader for lie_learn/spaces/spherical_quadrature.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/groups/SO3.py to SO3.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/irrep_bases.py to irrep_bases.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/representations/SO3/pinchon_hoggan/pinchon_hoggan.py to pinchon_hoggan.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lie_learn/spaces/spherical_quadrature.py to spherical_quadrature.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lie_learn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lie_learn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lie_learn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lie_learn.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lie_learn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "lie_learn.groups.__pycache__.SO3.cpython-36: module references __file__\n",
            "lie_learn.representations.SO3.__pycache__.irrep_bases.cpython-36: module references __file__\n",
            "lie_learn.representations.SO3.__pycache__.spherical_harmonics.cpython-36: module references __file__\n",
            "lie_learn.representations.SO3.pinchon_hoggan.__pycache__.pinchon_hoggan.cpython-36: module references __file__\n",
            "lie_learn.representations.SO3.pinchon_hoggan.__pycache__.pinchon_hoggan_dense.cpython-36: module references __file__\n",
            "lie_learn.spaces.__pycache__.spherical_quadrature.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/lie_learn-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing lie_learn-0.0.0-py3.6-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.6/dist-packages/lie_learn-0.0.0-py3.6-linux-x86_64.egg\n",
            "Extracting lie_learn-0.0.0-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding lie-learn 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/lie_learn-0.0.0-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for lie-learn==0.0.0\n",
            "Searching for numpy==1.17.5\n",
            "Best match: numpy 1.17.5\n",
            "Adding numpy 1.17.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for requests==2.21.0\n",
            "Best match: requests 2.21.0\n",
            "Adding requests 2.21.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Cython==0.29.14\n",
            "Best match: Cython 0.29.14\n",
            "Adding Cython 0.29.14 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for certifi==2019.11.28\n",
            "Best match: certifi 2019.11.28\n",
            "Adding certifi 2019.11.28 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for idna==2.8\n",
            "Best match: idna 2.8\n",
            "Adding idna 2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for lie-learn==0.0.0\n",
            "Start to download file ID 0B5e7DAOiLEZwSkdfXzBYT29Nc3c from google drive into /usr/local/lib/python3.6/dist-packages/lie_learn/representations/SO3/pinchon_hoggan/J_dense_0-278.npy\n",
            "/content\n",
            "Collecting pynvrtc\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/ad/79cbfaaa325270607735c9673a87b30daf578eae7946308333aa484dc1ef/pynvrtc-9.2.tar.gz\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.14.1)\n",
            "Building wheels for collected packages: pynvrtc\n",
            "  Building wheel for pynvrtc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynvrtc: filename=pynvrtc-9.2-cp36-none-any.whl size=7516 sha256=92bc94afedd2c87cfc7151b766b8994aabee9571de791f01a34bdd674fa75f70\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/f7/e8/264aa69f9a40d9cdc190dfdb6f21d94ec3322009d127438230\n",
            "Successfully built pynvrtc\n",
            "Installing collected packages: pynvrtc\n",
            "Successfully installed pynvrtc-9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4SwAM-Ck3pK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbGBycG-k3B2",
        "colab_type": "code",
        "outputId": "8d5ee00c-12b5-42ed-b845-8fae78aa4b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='/home/CIFAR-10 Classifier Using CNN in PyTorch/data/', \n",
        "                                        train=True,\n",
        "                                        download=True, \n",
        "                                        transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                          shuffle=False)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                       train=False,\n",
        "                                       download=True, \n",
        "                                       transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/CIFAR-10 Classifier Using CNN in PyTorch/data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:03, 42918352.34it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /home/CIFAR-10 Classifier Using CNN in PyTorch/data/cifar-10-python.tar.gz to /home/CIFAR-10 Classifier Using CNN in PyTorch/data/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:04, 42419777.32it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47x6xcAWncsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []\n",
        "for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            train_images.append(inputs)\n",
        "            train_labels.append(labels)\n",
        "\n",
        "for i, data in enumerate(testloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            test_images.append(inputs)\n",
        "            test_labels.append(labels)\n",
        "                        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFYt4gQwnb5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar_train = {}\n",
        "cifar_test = {}\n",
        "cifar_train['images'] = torch.stack(train_images).permute(0,3,4,2,1).numpy()\n",
        "cifar_train['labels'] = torch.stack(train_labels).numpy()\n",
        "cifar_test['labels'] = torch.stack(test_labels).numpy()\n",
        "cifar_test['images'] = torch.stack(test_images).permute(0,3,4,2,1).numpy()\n",
        "cifar_test['images'] = cifar_test['images'].reshape(10000,32,32,3)\n",
        "cifar_train['images'] = cifar_train['images'].reshape(50000,32,32,3)\n",
        "cifar_test['labels'] = cifar_test['labels'].reshape(10000)\n",
        "cifar_train['labels'] = cifar_train['labels'].reshape(50000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3Iu59-2SnhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def grayscale(images):\n",
        "  def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870,0.1140])\n",
        "  gray = []\n",
        "  for image in images:\n",
        "    gray.append(rgb2gray(image))\n",
        "  return   np.array(gray)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIvnAOA-c8Zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar_train['images'] = grayscale(cifar_train['images'])\n",
        "cifar_test['images'] = grayscale(cifar_test['images'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHJrrYTvdHgQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "4140aec3-7247-4b14-d7f7-b1c342330676"
      },
      "source": [
        "# cifar_test['images'][0]\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(train_images[8].reshape(3,32,32).permute(1,2,0).numpy())\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nniPKTWIqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xolKCCtOU-N0",
        "colab_type": "code",
        "outputId": "e76dc8f5-b0be-4af5-81c2-0c6be58f1801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "'''Module to generate the spherical cifar data set'''\n",
        "%cd /content\n",
        "import gzip\n",
        "import pickle\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import lie_learn.spaces.S2 as S2\n",
        "from torchvision import datasets\n",
        "from sklearn import preprocessing\n",
        "import torchvision.transforms as transforms\n",
        "NORTHPOLE_EPSILON = 1e-3\n",
        "\n",
        "\n",
        "def rand_rotation_matrix(deflection=1.0, randnums=None):\n",
        "    \"\"\"\n",
        "    Creates a random rotation matrix.\n",
        "\n",
        "    deflection: the magnitude of the rotation. For 0, no rotation; for 1, competely random\n",
        "    rotation. Small deflection => small perturbation.\n",
        "    randnums: 3 random numbers in the range [0, 1]. If `None`, they will be auto-generated.\n",
        "\n",
        "    # http://blog.lostinmyterminal.com/python/2015/05/12/random-rotation-matrix.html\n",
        "    \"\"\"\n",
        "\n",
        "    if randnums is None:\n",
        "        randnums = np.random.uniform(size=(3,))\n",
        "\n",
        "    theta, phi, z = randnums\n",
        "\n",
        "    theta = theta * 2.0*deflection*np.pi  # Rotation about the pole (Z).\n",
        "    phi = phi * 2.0*np.pi  # For direction of pole deflection.\n",
        "    z = z * 2.0*deflection  # For magnitude of pole deflection.\n",
        "\n",
        "    # Compute a vector V used for distributing points over the sphere\n",
        "    # via the reflection I - V Transpose(V).  This formulation of V\n",
        "    # will guarantee that if x[1] and x[2] are uniformly distributed,\n",
        "    # the reflected points will be uniform on the sphere.  Note that V\n",
        "    # has length sqrt(2) to eliminate the 2 in the Householder matrix.\n",
        "\n",
        "    r = np.sqrt(z)\n",
        "    V = (\n",
        "        np.sin(phi) * r,\n",
        "        np.cos(phi) * r,\n",
        "        np.sqrt(2.0 - z)\n",
        "    )\n",
        "\n",
        "    st = np.sin(theta)\n",
        "    ct = np.cos(theta)\n",
        "\n",
        "    R = np.array(((ct, st, 0), (-st, ct, 0), (0, 0, 1)))\n",
        "\n",
        "    # Construct the rotation matrix  ( V Transpose(V) - I ) R.\n",
        "\n",
        "    M = (np.outer(V, V) - np.eye(3)).dot(R)\n",
        "    return M\n",
        "\n",
        "\n",
        "def rotate_grid(rot, grid):\n",
        "    x, y, z = grid\n",
        "    xyz = np.array((x, y, z))\n",
        "    x_r, y_r, z_r = np.einsum('ij,jab->iab', rot, xyz)\n",
        "    return x_r, y_r, z_r\n",
        "\n",
        "\n",
        "def get_projection_grid(b, grid_type=\"Driscoll-Healy\"):\n",
        "    ''' returns the spherical grid in euclidean\n",
        "    coordinates, where the sphere's center is moved\n",
        "    to (0, 0, 1)'''\n",
        "    theta, phi = S2.meshgrid(b=b, grid_type=grid_type)\n",
        "    x_ = np.sin(theta) * np.cos(phi)\n",
        "    y_ = np.sin(theta) * np.sin(phi)\n",
        "    z_ = np.cos(theta)\n",
        "    return x_, y_, z_\n",
        "\n",
        "\n",
        "def project_sphere_on_xy_plane(grid, projection_origin):\n",
        "    ''' returns xy coordinates on the plane\n",
        "    obtained from projecting each point of\n",
        "    the spherical grid along the ray from\n",
        "    the projection origin through the sphere '''\n",
        "\n",
        "    sx, sy, sz = projection_origin\n",
        "    x, y, z = grid\n",
        "    z = z.copy() + 1\n",
        "\n",
        "    t = -z / (z - sz)\n",
        "    qx = t * (x - sx) + x\n",
        "    qy = t * (y - sy) + y\n",
        "\n",
        "    xmin = 1/2 * (-1 - sx) + -1\n",
        "    ymin = 1/2 * (-1 - sy) + -1\n",
        "\n",
        "    # ensure that plane projection\n",
        "    # ends up on southern hemisphere\n",
        "    rx = (qx - xmin) / (2 * np.abs(xmin))\n",
        "    ry = (qy - ymin) / (2 * np.abs(ymin))\n",
        "\n",
        "    return rx, ry\n",
        "\n",
        "\n",
        "def sample_within_bounds(signal, x, y, bounds):\n",
        "    ''' '''\n",
        "    xmin, xmax, ymin, ymax = bounds\n",
        "\n",
        "    idxs = (xmin <= x) & (x < xmax) & (ymin <= y) & (y < ymax)\n",
        "\n",
        "    if len(signal.shape) > 2:\n",
        "        sample = np.zeros((signal.shape[0], x.shape[0], x.shape[1]))\n",
        "        sample[:, idxs] = signal[:, x[idxs], y[idxs]]\n",
        "    else:\n",
        "        sample = np.zeros((x.shape[0], x.shape[1]))\n",
        "        sample[idxs] = signal[x[idxs], y[idxs]]\n",
        "    return sample\n",
        "\n",
        "\n",
        "def sample_bilinear(signal, rx, ry):\n",
        "    ''' '''\n",
        "\n",
        "    signal_dim_x = signal.shape[1]\n",
        "    signal_dim_y = signal.shape[2]\n",
        "\n",
        "    rx *= signal_dim_x\n",
        "    ry *= signal_dim_y\n",
        "\n",
        "    # discretize sample position\n",
        "    ix = rx.astype(int)\n",
        "    iy = ry.astype(int)\n",
        "\n",
        "    # obtain four sample coordinates\n",
        "    ix0 = ix - 1\n",
        "    iy0 = iy - 1\n",
        "    ix1 = ix + 1\n",
        "    iy1 = iy + 1\n",
        "\n",
        "    bounds = (0, signal_dim_x, 0, signal_dim_y)\n",
        "\n",
        "    # sample signal at each four positions\n",
        "    signal_00 = sample_within_bounds(signal, ix0, iy0, bounds)\n",
        "    signal_10 = sample_within_bounds(signal, ix1, iy0, bounds)\n",
        "    signal_01 = sample_within_bounds(signal, ix0, iy1, bounds)\n",
        "    signal_11 = sample_within_bounds(signal, ix1, iy1, bounds)\n",
        "\n",
        "    # linear interpolation in x-direction\n",
        "    fx1 = (ix1-rx) * signal_00 + (rx-ix0) * signal_10\n",
        "    fx2 = (ix1-rx) * signal_01 + (rx-ix0) * signal_11\n",
        "\n",
        "    # linear interpolation in y-direction\n",
        "    return (iy1 - ry) * fx1 + (ry - iy0) * fx2\n",
        "\n",
        "\n",
        "def project_2d_on_sphere(signal, grid, projection_origin=None):\n",
        "    ''' '''\n",
        "    if projection_origin is None:\n",
        "        projection_origin = (0, 0, 2 + NORTHPOLE_EPSILON)\n",
        "\n",
        "    rx, ry = project_sphere_on_xy_plane(grid, projection_origin)\n",
        "    sample = sample_bilinear(signal, rx, ry)\n",
        "\n",
        "    # ensure that only south hemisphere gets projected\n",
        "    sample *= (grid[2] <= 1).astype(np.float64)\n",
        "\n",
        "    # rescale signal to [0,1]\n",
        "    sample_min = sample.min(axis=(1, 2)).reshape(-1, 1, 1)\n",
        "    sample_max = sample.max(axis=(1, 2)).reshape(-1, 1, 1)\n",
        "\n",
        "    sample = (sample - sample_min) / (sample_max - sample_min)\n",
        "    sample *= 255\n",
        "    sample = sample.astype(np.uint8)\n",
        "\n",
        "    return sample\n",
        "\n",
        "def main():\n",
        "    args = {}\n",
        "    args['bandwidth'] = 30\n",
        "    args['chunk_size'] = 1\n",
        "    args['noise'] = 1\n",
        "    args['chunk_size'] = 1\n",
        "    args['cifar_data_folder'] = \"CIFAR_data\"\n",
        "    args['mnist_data_folder'] = \"MNIST_data\"\n",
        "    args['output_file'] = \"s2_cifar.gz\"\n",
        "    args['no_rotate_train'] = True\n",
        "    args['no_rotate_test'] = True\n",
        "\n",
        "    grid = get_projection_grid(b=args['bandwidth'])\n",
        "    # result\n",
        "    dataset = {}\n",
        "\n",
        "    no_rotate = {\"train\": args[\"no_rotate_train\"], \"test\": args[\"no_rotate_test\"]}\n",
        "\n",
        "    for label, data in zip([\"train\", \"test\"], [cifar_train, cifar_test]):\n",
        "\n",
        "        print(\"projecting {0} data set\".format(label))\n",
        "        current = 0\n",
        "        signals = data['images'].reshape(-1, 32, 32).astype(np.float64)\n",
        "        n_signals = signals.shape[0]\n",
        "        projections = np.ndarray(\n",
        "            (signals.shape[0], 2 * args[\"bandwidth\"], 2 * args[\"bandwidth\"]),\n",
        "            dtype=np.uint8)\n",
        "\n",
        "        while current < n_signals:\n",
        "\n",
        "            if not no_rotate[label]:\n",
        "                rot = rand_rotation_matrix(deflection=args[\"noise\"])\n",
        "                rotated_grid = rotate_grid(rot, grid)\n",
        "            else:\n",
        "                rotated_grid = grid\n",
        "\n",
        "            idxs = np.arange(current, min(n_signals,\n",
        "                                          current + args[\"chunk_size\"]))\n",
        "            chunk = signals[idxs]\n",
        "            projections[idxs] = project_2d_on_sphere(chunk, rotated_grid)\n",
        "            current += args[\"chunk_size\"]\n",
        "            print(\"\\r{0}/{1}\".format(current, n_signals), end=\"\")\n",
        "        print(\"\")\n",
        "\n",
        "        dataset[label] = {\n",
        "            'images': projections,\n",
        "            'labels': data['labels']\n",
        "        }\n",
        "    print(\"writing pickle\")\n",
        "    with gzip.open(args[\"output_file\"], 'wb') as f:\n",
        "        pickle.dump(dataset, f)\n",
        "    print(\"done\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "projecting train data set\n",
            "50000/50000\n",
            "projecting test data set\n",
            "10000/10000\n",
            "writing pickle\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPODEZESb9kn",
        "colab_type": "text"
      },
      "source": [
        "SAVE THE CODE IN THE BELOW CELL IN CIFAF10 FOLDER LOCATED IN S2CNN/EXAMPLES AS '.py' FILE AND THEN RUN THE FILE AS !python run.py\n",
        "THIS IS DONE BECAUSE THE CODE IS UNABLE TO GET THE REQUIRED s2cnn MODULES WHEN RUN IN THE CELLS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLzd_EDxZA-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pylint: disable=E1101,R,C\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from s2cnn import SO3Convolution\n",
        "from s2cnn import S2Convolution\n",
        "from s2cnn import so3_integrate\n",
        "from s2cnn import so3_near_identity_grid\n",
        "from s2cnn import s2_near_identity_grid\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.utils.data as data_utils\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import argparse\n",
        "\n",
        "MNIST_PATH = \"s2_cifar.gz\"\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 5e-3\n",
        "\n",
        "\n",
        "def load_data(path, batch_size):\n",
        "\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "\n",
        "    train_data = torch.from_numpy(\n",
        "        dataset[\"train\"][\"images\"][:, None, :, :].astype(np.float32))\n",
        "    train_labels = torch.from_numpy(\n",
        "        dataset[\"train\"][\"labels\"].astype(np.int64))\n",
        "\n",
        "    # TODO normalize dataset\n",
        "    # mean = train_data.mean()\n",
        "    # stdv = train_data.std()\n",
        "\n",
        "    train_dataset = data_utils.TensorDataset(train_data, train_labels)\n",
        "    train_loader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    test_data = torch.from_numpy(\n",
        "        dataset[\"test\"][\"images\"][:, None, :, :].astype(np.float32))\n",
        "    test_labels = torch.from_numpy(\n",
        "        dataset[\"test\"][\"labels\"].astype(np.int64))\n",
        "\n",
        "    test_dataset = data_utils.TensorDataset(test_data, test_labels)\n",
        "    test_loader = data_utils.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader, train_dataset, test_dataset\n",
        "\n",
        "\n",
        "class S2ConvNet_original(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(S2ConvNet_original, self).__init__()\n",
        "\n",
        "        f1 = 20\n",
        "        f2 = 40\n",
        "        f_output = 10\n",
        "\n",
        "        b_in = 30\n",
        "        b_l1 = 10\n",
        "        b_l2 = 6\n",
        "\n",
        "        grid_s2 = s2_near_identity_grid()\n",
        "        grid_so3 = so3_near_identity_grid()\n",
        "\n",
        "        self.conv1 = S2Convolution(\n",
        "            nfeature_in=1,\n",
        "            nfeature_out=f1,\n",
        "            b_in=b_in,\n",
        "            b_out=b_l1,\n",
        "            grid=grid_s2)\n",
        "\n",
        "        self.conv2 = SO3Convolution(\n",
        "            nfeature_in=f1,\n",
        "            nfeature_out=f2,\n",
        "            b_in=b_l1,\n",
        "            b_out=b_l2,\n",
        "            grid=grid_so3)\n",
        "\n",
        "        self.out_layer = nn.Linear(f2, f_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = so3_integrate(x)\n",
        "\n",
        "        x = self.out_layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class S2ConvNet_deep(nn.Module):\n",
        "\n",
        "    def __init__(self, bandwidth=30):\n",
        "        super(S2ConvNet_deep, self).__init__()\n",
        "\n",
        "        grid_s2    =  s2_near_identity_grid(n_alpha=6, max_beta=np.pi/16, n_beta=1)\n",
        "        grid_so3_1 = so3_near_identity_grid(n_alpha=6, max_beta=np.pi/16, n_beta=1, max_gamma=2*np.pi, n_gamma=6)\n",
        "        grid_so3_2 = so3_near_identity_grid(n_alpha=6, max_beta=np.pi/ 8, n_beta=1, max_gamma=2*np.pi, n_gamma=6)\n",
        "        grid_so3_3 = so3_near_identity_grid(n_alpha=6, max_beta=np.pi/ 4, n_beta=1, max_gamma=2*np.pi, n_gamma=6)\n",
        "        grid_so3_4 = so3_near_identity_grid(n_alpha=6, max_beta=np.pi/ 2, n_beta=1, max_gamma=2*np.pi, n_gamma=6)\n",
        "\n",
        "        self.convolutional = nn.Sequential(\n",
        "            S2Convolution(\n",
        "                nfeature_in  = 1,\n",
        "                nfeature_out = 8,\n",
        "                b_in  = bandwidth,\n",
        "                b_out = bandwidth,\n",
        "                grid=grid_s2),\n",
        "            nn.ReLU(inplace=False),\n",
        "            SO3Convolution(\n",
        "                nfeature_in  =  8,\n",
        "                nfeature_out = 16,\n",
        "                b_in  = bandwidth,\n",
        "                b_out = bandwidth//2,\n",
        "                grid=grid_so3_1),\n",
        "            nn.ReLU(inplace=False),\n",
        "\n",
        "            SO3Convolution(\n",
        "                nfeature_in  = 16,\n",
        "                nfeature_out = 16,\n",
        "                b_in  = bandwidth//2,\n",
        "                b_out = bandwidth//2,\n",
        "                grid=grid_so3_2),\n",
        "            nn.ReLU(inplace=False),\n",
        "            SO3Convolution(\n",
        "                nfeature_in  = 16,\n",
        "                nfeature_out = 24,\n",
        "                b_in  = bandwidth//2,\n",
        "                b_out = bandwidth//4,\n",
        "                grid=grid_so3_2),\n",
        "            nn.ReLU(inplace=False),\n",
        "\n",
        "            SO3Convolution(\n",
        "                nfeature_in  = 24,\n",
        "                nfeature_out = 24,\n",
        "                b_in  = bandwidth//4,\n",
        "                b_out = bandwidth//4,\n",
        "                grid=grid_so3_3),\n",
        "            nn.ReLU(inplace=False),\n",
        "            SO3Convolution(\n",
        "                nfeature_in  = 24,\n",
        "                nfeature_out = 32,\n",
        "                b_in  = bandwidth//4,\n",
        "                b_out = bandwidth//8,\n",
        "                grid=grid_so3_3),\n",
        "            nn.ReLU(inplace=False),\n",
        "\n",
        "            SO3Convolution(\n",
        "                nfeature_in  = 32,\n",
        "                nfeature_out = 64,\n",
        "                b_in  = bandwidth//8,\n",
        "                b_out = bandwidth//8,\n",
        "                grid=grid_so3_4),\n",
        "            nn.ReLU(inplace=False)\n",
        "            )\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            # linear 1\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Linear(in_features=64,out_features=64),\n",
        "            nn.ReLU(inplace=False),\n",
        "            # linear 2\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Linear(in_features=64, out_features=32),\n",
        "            nn.ReLU(inplace=False),\n",
        "            # linear 3\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.Linear(in_features=32, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convolutional(x)\n",
        "        x = so3_integrate(x)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "def main(network):\n",
        "\n",
        "    train_loader, test_loader, train_dataset, _ = load_data(\n",
        "        MNIST_PATH, BATCH_SIZE)\n",
        "\n",
        "    if network == 'original':\n",
        "        classifier = S2ConvNet_original()\n",
        "    elif network == 'deep':\n",
        "        classifier = S2ConvNet_deep()\n",
        "    else:\n",
        "        raise ValueError('Unknown network architecture')\n",
        "    classifier.to(DEVICE)\n",
        "\n",
        "    print(\"#params\", sum(x.numel() for x in classifier.parameters()))\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    criterion = criterion.to(DEVICE)\n",
        "\n",
        "    optimizer = torch.optim.Adam(\n",
        "        classifier.parameters(),\n",
        "        lr=LEARNING_RATE)\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            classifier.train()\n",
        "\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = classifier(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            print('\\rEpoch [{0}/{1}], Iter [{2}/{3}] Loss: {4:.4f}'.format(\n",
        "                epoch+1, NUM_EPOCHS, i+1, len(train_dataset)//BATCH_SIZE,\n",
        "                loss.item()), end=\"\")\n",
        "        print(\"\")\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_loader:\n",
        "\n",
        "            classifier.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                images = images.to(DEVICE)\n",
        "                labels = labels.to(DEVICE)\n",
        "\n",
        "                outputs = classifier(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).long().sum().item()\n",
        "\n",
        "        print('Test Accuracy: {0}'.format(100 * correct / total))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    network = \"deep\" #deep\\original\n",
        "\n",
        "    main(network)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcoO6gd2YVWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4815d094-7745-4e11-d4ce-aa38728b639e"
      },
      "source": [
        "%cd /content/s2cnn/examples/\n",
        "!mkdir cifar10\n",
        "!cp /content/s2_cifar.gz cifar10/\n",
        "%cd cifar10/\n",
        "!python run.py"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/s2cnn/examples\n",
            "mkdir: cannot create directory cifar10: File exists\n",
            "/content/s2cnn/examples/cifar10\n",
            "#params 156882\n",
            "compute 0.pkl.gz... save 0.pkl.gz... done\n",
            "compute 0.pkl.gz... save 0.pkl.gz... done\n",
            "compute 0.pkl.gz... save 0.pkl.gz... done\n",
            "compute 1.pkl.gz... save 1.pkl.gz... done\n",
            "compute 0.pkl.gz... save 0.pkl.gz... done\n",
            "compute 2.pkl.gz... save 2.pkl.gz... done\n",
            "compute 3.pkl.gz... save 3.pkl.gz... done\n",
            "compute 1.pkl.gz... save 1.pkl.gz... done\n",
            "compute 4.pkl.gz... save 4.pkl.gz... done\n",
            "compute 2.pkl.gz... save 2.pkl.gz... done\n",
            "compute 5.pkl.gz... save 5.pkl.gz... done\n",
            "compute 6.pkl.gz... save 6.pkl.gz... done\n",
            "compute 3.pkl.gz... save 3.pkl.gz... done\n",
            "compute 7.pkl.gz... save 7.pkl.gz... done\n",
            "compute 4.pkl.gz... save 4.pkl.gz... done\n",
            "compute 8.pkl.gz... save 8.pkl.gz... done\n",
            "compute 9.pkl.gz... save 9.pkl.gz... done\n",
            "compute 5.pkl.gz... save 5.pkl.gz... done\n",
            "Epoch [1/20], Iter [1563/1562] Loss: 1.4845\n",
            "Test Accuracy: 29.87\n",
            "Epoch [2/20], Iter [1563/1562] Loss: 1.9222\n",
            "Test Accuracy: 24.09\n",
            "Epoch [3/20], Iter [1563/1562] Loss: 1.1250\n",
            "Test Accuracy: 51.87\n",
            "Epoch [4/20], Iter [1563/1562] Loss: 1.1882\n",
            "Test Accuracy: 39.74\n",
            "Epoch [5/20], Iter [1563/1562] Loss: 1.4185\n",
            "Test Accuracy: 51.68\n",
            "Epoch [6/20], Iter [1563/1562] Loss: 1.1474\n",
            "Test Accuracy: 36.86\n",
            "Epoch [7/20], Iter [1563/1562] Loss: 0.8707\n",
            "Test Accuracy: 54.56\n",
            "Epoch [8/20], Iter [1563/1562] Loss: 0.9882\n",
            "Test Accuracy: 55.32\n",
            "Epoch [9/20], Iter [1563/1562] Loss: 1.6369\n",
            "Test Accuracy: 60.17\n",
            "Epoch [10/20], Iter [1563/1562] Loss: 1.1535\n",
            "Test Accuracy: 57.43\n",
            "Epoch [11/20], Iter [1563/1562] Loss: 1.0311\n",
            "Test Accuracy: 51.96\n",
            "Epoch [12/20], Iter [1563/1562] Loss: 0.8331\n",
            "Test Accuracy: 58.53\n",
            "Epoch [13/20], Iter [1563/1562] Loss: 2.1877\n",
            "Test Accuracy: 59.45\n",
            "Epoch [14/20], Iter [1563/1562] Loss: 0.6300\n",
            "Test Accuracy: 62.38\n",
            "Epoch [15/20], Iter [1563/1562] Loss: 0.7933\n",
            "Test Accuracy: 58.34\n",
            "Epoch [16/20], Iter [1563/1562] Loss: 1.0580\n",
            "Test Accuracy: 61.19\n",
            "Epoch [17/20], Iter [1563/1562] Loss: 0.4755\n",
            "Test Accuracy: 60.87\n",
            "Epoch [18/20], Iter [1563/1562] Loss: 0.9598\n",
            "Test Accuracy: 63.23\n",
            "Epoch [19/20], Iter [1563/1562] Loss: 1.0384\n",
            "Test Accuracy: 64.81\n",
            "Epoch [20/20], Iter [1563/1562] Loss: 0.8749\n",
            "Test Accuracy: 63.01\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}